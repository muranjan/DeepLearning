{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleTitanic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a2k8TeVjm6i",
        "colab_type": "code",
        "outputId": "ec4d54ce-21b8-4582-c89a-b6fad12f0f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Required Packages\n",
        "#!pip install -q pandas_profiling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "import time\n",
        "from datetime import timedelta"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8188nOVnYZk",
        "colab_type": "code",
        "outputId": "a95eea62-8668-40a3-82b0-f06cb864fa55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# some configuratin flags and variables\n",
        "verbose=1 # Use in classifier\n",
        "\n",
        "# Input files\n",
        "train_url='https://raw.githubusercontent.com/muranjan/datarepo/master/titanic/train.csv'\n",
        "test_url='https://raw.githubusercontent.com/muranjan/datarepo/master/titanic/test.csv'\n",
        "\n",
        "# defeine random seed for reproducibility\n",
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "\n",
        "# read training data\n",
        "train = pd.read_csv(train_url,index_col='PassengerId')\n",
        "\n",
        "print(train.shape)\n",
        "print(train.columns)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(891, 11)\n",
            "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket',\n",
            "       'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoMBfUHQC3U2",
        "colab_type": "code",
        "outputId": "1aa0c74d-4705-44cc-a8d4-520aee1f3916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "# preview the training dara\n",
        "#pandas_profiling.ProfileReport(train)\n",
        "# getting error pandas_profiling like TypeError: concat() got an unexpected keyword argument 'join_axes' \n",
        "train[:10]\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Survived  Pclass  ... Cabin Embarked\n",
              "PassengerId                    ...               \n",
              "1                   0       3  ...   NaN        S\n",
              "2                   1       1  ...   C85        C\n",
              "3                   1       3  ...   NaN        S\n",
              "4                   1       1  ...  C123        S\n",
              "5                   0       3  ...   NaN        S\n",
              "6                   0       3  ...   NaN        Q\n",
              "7                   0       1  ...   E46        S\n",
              "8                   0       3  ...   NaN        S\n",
              "9                   1       3  ...   NaN        S\n",
              "10                  1       2  ...   NaN        C\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i8Y5a6jDZZ4",
        "colab_type": "code",
        "outputId": "64a47bcf-9814-49ea-bbed-aa73853ef1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train.isnull().sum()\n",
        "#train['Embarked'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived      0\n",
              "Pclass        0\n",
              "Name          0\n",
              "Sex           0\n",
              "Age         177\n",
              "SibSp         0\n",
              "Parch         0\n",
              "Ticket        0\n",
              "Fare          0\n",
              "Cabin       687\n",
              "Embarked      2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va6nSo0KDmJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FeatureEngineering(df):\n",
        "    # Drop unwanted features\n",
        "    df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
        "    \n",
        "    # Fill missing data: Age and Fare with the mean, Embarked with most frequent value\n",
        "    df[['Age']]       = df[['Age']].fillna(value=df[['Age']].mean())\n",
        "    df[['Fare']]      = df[['Fare']].fillna(value=df[['Fare']].mean())\n",
        "    df[['Embarked']]  = df[['Embarked']].fillna(value=df['Embarked'].value_counts().idxmax())\n",
        "    \n",
        "    # Convert categorical  features into numeric\n",
        "    df['Sex'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "      \n",
        "    # Convert Embarked to one-hot\n",
        "    enbarked_one_hot = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
        "    df = df.drop('Embarked', axis=1)\n",
        "    df = df.join(enbarked_one_hot)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HrqBmhNIGhf",
        "colab_type": "code",
        "outputId": "fa7ffd6b-586a-487c-b91e-443ff278f4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train = FeatureEngineering(train)\n",
        "train.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived      0\n",
              "Pclass        0\n",
              "Sex           0\n",
              "Age           0\n",
              "SibSp         0\n",
              "Parch         0\n",
              "Fare          0\n",
              "Embarked_C    0\n",
              "Embarked_Q    0\n",
              "Embarked_S    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xa3erfqIOcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create X & Y from the train data where Y will have target variable i.e Survived\n",
        "X = train.drop(['Survived'], axis=1).values.astype(float)\n",
        "Y = train['Survived'].values\n",
        "# It is almost always a good idea to perform some scaling of input values when using neural network models (jb).\n",
        "\n",
        "scale = StandardScaler()\n",
        "X = scale.fit_transform(X)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDmmF5eHXB-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(optimizer='adam', init='uniform'):\n",
        "    # create model\n",
        "    if verbose: print(\"**Create model with optimizer: %s; init: %s\" % (optimizer, init) )\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=X.shape[1], kernel_initializer=init, activation='relu'))\n",
        "    model.add(Dense(8, kernel_initializer=init, activation='relu'))\n",
        "    model.add(Dense(4, kernel_initializer=init, activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWLGF36dXQUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_gridsearch = False\n",
        "\n",
        "if run_gridsearch:\n",
        "    \n",
        "    start_time = time.time()\n",
        "    if verbose: print (time.strftime( \"%H:%M:%S \" + \"GridSearch started ... \" ) )\n",
        "    optimizers = ['rmsprop', 'adam']\n",
        "    inits = ['glorot_uniform', 'normal', 'uniform']\n",
        "    epochs = [50, 100, 200]\n",
        "    batches = [5, 10]\n",
        "    \n",
        "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "    \n",
        "    param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "    grid_result = grid.fit(X, Y)\n",
        "    \n",
        "    # summarize results\n",
        "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "    means = grid_result.cv_results_['mean_test_score']\n",
        "    stds = grid_result.cv_results_['std_test_score']\n",
        "    params = grid_result.cv_results_['params']\n",
        "    if verbose: \n",
        "        for mean, stdev, param in zip(means, stds, params):\n",
        "            print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "        elapsed_time = time.time() - start_time  \n",
        "        print (\"Time elapsed: \",timedelta(seconds=elapsed_time))\n",
        "        \n",
        "    best_epochs = grid_result.best_params_['epochs']\n",
        "    best_batch_size = grid_result.best_params_['batch_size']\n",
        "    best_init = grid_result.best_params_['init']\n",
        "    best_optimizer = grid_result.best_params_['optimizer']\n",
        "    \n",
        "else:\n",
        "    # pre-selected paramters\n",
        "    best_epochs = 200\n",
        "    best_batch_size = 5\n",
        "    best_init = 'glorot_uniform'\n",
        "    best_optimizer = 'rmsprop'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrQOypsDbpNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a30073fd-c5d8-406d-9077-efe7f411b64a"
      },
      "source": [
        "# Create a classifier with best parameters\n",
        "model_pred = KerasClassifier(build_fn=create_model, optimizer=best_optimizer, init=best_init, epochs=best_epochs, batch_size=best_batch_size, verbose=verbose)\n",
        "model_pred.fit(X, Y)\n",
        "\n",
        "# Read test data\n",
        "test_df = pd.read_csv(test_url,index_col='PassengerId')\n",
        "# Prep and clean data\n",
        "test_df = FeatureEngineering(test_df)\n",
        "# Create X_test\n",
        "X_test = test_df.values.astype(float)\n",
        "# Scaling\n",
        "X_test = scale.transform(X_test)\n",
        "\n",
        "# Predict 'Survived'\n",
        "prediction = model_pred.predict(X_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**Create model with optimizer: rmsprop; init: glorot_uniform\n",
            "Epoch 1/200\n",
            "891/891 [==============================] - 1s 594us/step - loss: 0.6640 - accuracy: 0.6510\n",
            "Epoch 2/200\n",
            "891/891 [==============================] - 0s 479us/step - loss: 0.6068 - accuracy: 0.7845\n",
            "Epoch 3/200\n",
            "891/891 [==============================] - 0s 489us/step - loss: 0.5686 - accuracy: 0.8036\n",
            "Epoch 4/200\n",
            "891/891 [==============================] - 0s 484us/step - loss: 0.5385 - accuracy: 0.8058\n",
            "Epoch 5/200\n",
            "891/891 [==============================] - 0s 534us/step - loss: 0.5151 - accuracy: 0.8148\n",
            "Epoch 6/200\n",
            "891/891 [==============================] - 0s 483us/step - loss: 0.4949 - accuracy: 0.8283\n",
            "Epoch 7/200\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.4780 - accuracy: 0.8215\n",
            "Epoch 8/200\n",
            "891/891 [==============================] - 0s 516us/step - loss: 0.4589 - accuracy: 0.8283\n",
            "Epoch 9/200\n",
            "891/891 [==============================] - 0s 538us/step - loss: 0.4397 - accuracy: 0.8294\n",
            "Epoch 10/200\n",
            "891/891 [==============================] - 0s 523us/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 11/200\n",
            "891/891 [==============================] - 0s 513us/step - loss: 0.4195 - accuracy: 0.8305\n",
            "Epoch 12/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.4143 - accuracy: 0.8316\n",
            "Epoch 13/200\n",
            "891/891 [==============================] - 0s 528us/step - loss: 0.4111 - accuracy: 0.8305\n",
            "Epoch 14/200\n",
            "891/891 [==============================] - 0s 515us/step - loss: 0.4089 - accuracy: 0.8316\n",
            "Epoch 15/200\n",
            "891/891 [==============================] - 0s 554us/step - loss: 0.4070 - accuracy: 0.8283\n",
            "Epoch 16/200\n",
            "891/891 [==============================] - 0s 530us/step - loss: 0.4050 - accuracy: 0.8316\n",
            "Epoch 17/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.4037 - accuracy: 0.8305\n",
            "Epoch 18/200\n",
            "891/891 [==============================] - 0s 547us/step - loss: 0.4014 - accuracy: 0.8350\n",
            "Epoch 19/200\n",
            "891/891 [==============================] - 0s 526us/step - loss: 0.4009 - accuracy: 0.8328\n",
            "Epoch 20/200\n",
            "891/891 [==============================] - 0s 508us/step - loss: 0.3991 - accuracy: 0.8395\n",
            "Epoch 21/200\n",
            "891/891 [==============================] - 0s 526us/step - loss: 0.3965 - accuracy: 0.8418\n",
            "Epoch 22/200\n",
            "891/891 [==============================] - 0s 504us/step - loss: 0.3950 - accuracy: 0.8429\n",
            "Epoch 23/200\n",
            "891/891 [==============================] - 0s 511us/step - loss: 0.3943 - accuracy: 0.8395\n",
            "Epoch 24/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.3929 - accuracy: 0.8440\n",
            "Epoch 25/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.3922 - accuracy: 0.8406\n",
            "Epoch 26/200\n",
            "891/891 [==============================] - 0s 546us/step - loss: 0.3922 - accuracy: 0.8395\n",
            "Epoch 27/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.3906 - accuracy: 0.8440\n",
            "Epoch 28/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3887 - accuracy: 0.8462\n",
            "Epoch 29/200\n",
            "891/891 [==============================] - 0s 475us/step - loss: 0.3911 - accuracy: 0.8418\n",
            "Epoch 30/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.3898 - accuracy: 0.8462\n",
            "Epoch 31/200\n",
            "891/891 [==============================] - 0s 479us/step - loss: 0.3894 - accuracy: 0.8440\n",
            "Epoch 32/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.3885 - accuracy: 0.8462\n",
            "Epoch 33/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3884 - accuracy: 0.8429\n",
            "Epoch 34/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3891 - accuracy: 0.8429\n",
            "Epoch 35/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.3871 - accuracy: 0.8462\n",
            "Epoch 36/200\n",
            "891/891 [==============================] - 0s 496us/step - loss: 0.3873 - accuracy: 0.8418\n",
            "Epoch 37/200\n",
            "891/891 [==============================] - 0s 484us/step - loss: 0.3863 - accuracy: 0.8462\n",
            "Epoch 38/200\n",
            "891/891 [==============================] - 0s 474us/step - loss: 0.3846 - accuracy: 0.8451\n",
            "Epoch 39/200\n",
            "891/891 [==============================] - 0s 538us/step - loss: 0.3873 - accuracy: 0.8440\n",
            "Epoch 40/200\n",
            "891/891 [==============================] - 0s 491us/step - loss: 0.3839 - accuracy: 0.8485\n",
            "Epoch 41/200\n",
            "891/891 [==============================] - 0s 492us/step - loss: 0.3845 - accuracy: 0.8496\n",
            "Epoch 42/200\n",
            "891/891 [==============================] - 0s 494us/step - loss: 0.3841 - accuracy: 0.8496\n",
            "Epoch 43/200\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.3837 - accuracy: 0.8406\n",
            "Epoch 44/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.3846 - accuracy: 0.8440\n",
            "Epoch 45/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3838 - accuracy: 0.8440\n",
            "Epoch 46/200\n",
            "891/891 [==============================] - 0s 534us/step - loss: 0.3818 - accuracy: 0.8462\n",
            "Epoch 47/200\n",
            "891/891 [==============================] - 0s 473us/step - loss: 0.3817 - accuracy: 0.8474\n",
            "Epoch 48/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3820 - accuracy: 0.8429\n",
            "Epoch 49/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3804 - accuracy: 0.8440\n",
            "Epoch 50/200\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.3796 - accuracy: 0.8429\n",
            "Epoch 51/200\n",
            "891/891 [==============================] - 0s 531us/step - loss: 0.3793 - accuracy: 0.8429\n",
            "Epoch 52/200\n",
            "891/891 [==============================] - 0s 470us/step - loss: 0.3803 - accuracy: 0.8496\n",
            "Epoch 53/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.3804 - accuracy: 0.8406\n",
            "Epoch 54/200\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.3799 - accuracy: 0.8440\n",
            "Epoch 55/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3794 - accuracy: 0.8485\n",
            "Epoch 56/200\n",
            "891/891 [==============================] - 0s 504us/step - loss: 0.3810 - accuracy: 0.8429\n",
            "Epoch 57/200\n",
            "891/891 [==============================] - 0s 513us/step - loss: 0.3789 - accuracy: 0.8485\n",
            "Epoch 58/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3762 - accuracy: 0.8474\n",
            "Epoch 59/200\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.3790 - accuracy: 0.8440\n",
            "Epoch 60/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.3788 - accuracy: 0.8519\n",
            "Epoch 61/200\n",
            "891/891 [==============================] - 0s 475us/step - loss: 0.3769 - accuracy: 0.8496\n",
            "Epoch 62/200\n",
            "891/891 [==============================] - 0s 554us/step - loss: 0.3814 - accuracy: 0.8485\n",
            "Epoch 63/200\n",
            "891/891 [==============================] - 0s 471us/step - loss: 0.3779 - accuracy: 0.8462\n",
            "Epoch 64/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3772 - accuracy: 0.8429\n",
            "Epoch 65/200\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.3783 - accuracy: 0.8462\n",
            "Epoch 66/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.3771 - accuracy: 0.8507\n",
            "Epoch 67/200\n",
            "891/891 [==============================] - 0s 504us/step - loss: 0.3766 - accuracy: 0.8485\n",
            "Epoch 68/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.3747 - accuracy: 0.8507\n",
            "Epoch 69/200\n",
            "891/891 [==============================] - 0s 530us/step - loss: 0.3793 - accuracy: 0.8485\n",
            "Epoch 70/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.3769 - accuracy: 0.8496\n",
            "Epoch 71/200\n",
            "891/891 [==============================] - 0s 532us/step - loss: 0.3746 - accuracy: 0.8474\n",
            "Epoch 72/200\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.3766 - accuracy: 0.8474\n",
            "Epoch 73/200\n",
            "891/891 [==============================] - 0s 502us/step - loss: 0.3755 - accuracy: 0.8519\n",
            "Epoch 74/200\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.3748 - accuracy: 0.8507\n",
            "Epoch 75/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.3749 - accuracy: 0.8496\n",
            "Epoch 76/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.3722 - accuracy: 0.8451\n",
            "Epoch 77/200\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.3776 - accuracy: 0.8530\n",
            "Epoch 78/200\n",
            "891/891 [==============================] - 0s 524us/step - loss: 0.3751 - accuracy: 0.8530\n",
            "Epoch 79/200\n",
            "891/891 [==============================] - 0s 460us/step - loss: 0.3712 - accuracy: 0.8485\n",
            "Epoch 80/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3750 - accuracy: 0.8541\n",
            "Epoch 81/200\n",
            "891/891 [==============================] - 0s 473us/step - loss: 0.3741 - accuracy: 0.8496\n",
            "Epoch 82/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3749 - accuracy: 0.8541\n",
            "Epoch 83/200\n",
            "891/891 [==============================] - 0s 490us/step - loss: 0.3723 - accuracy: 0.8451\n",
            "Epoch 84/200\n",
            "891/891 [==============================] - 0s 479us/step - loss: 0.3746 - accuracy: 0.8552\n",
            "Epoch 85/200\n",
            "891/891 [==============================] - 0s 507us/step - loss: 0.3725 - accuracy: 0.8530\n",
            "Epoch 86/200\n",
            "891/891 [==============================] - 0s 486us/step - loss: 0.3721 - accuracy: 0.8462\n",
            "Epoch 87/200\n",
            "891/891 [==============================] - 0s 505us/step - loss: 0.3727 - accuracy: 0.8530\n",
            "Epoch 88/200\n",
            "891/891 [==============================] - 0s 487us/step - loss: 0.3705 - accuracy: 0.8519\n",
            "Epoch 89/200\n",
            "891/891 [==============================] - 0s 542us/step - loss: 0.3758 - accuracy: 0.8541\n",
            "Epoch 90/200\n",
            "891/891 [==============================] - 0s 469us/step - loss: 0.3693 - accuracy: 0.8507\n",
            "Epoch 91/200\n",
            "891/891 [==============================] - 0s 501us/step - loss: 0.3736 - accuracy: 0.8496\n",
            "Epoch 92/200\n",
            "891/891 [==============================] - 0s 475us/step - loss: 0.3705 - accuracy: 0.8563\n",
            "Epoch 93/200\n",
            "891/891 [==============================] - 0s 459us/step - loss: 0.3714 - accuracy: 0.8530\n",
            "Epoch 94/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.3710 - accuracy: 0.8485\n",
            "Epoch 95/200\n",
            "891/891 [==============================] - 0s 473us/step - loss: 0.3702 - accuracy: 0.8575\n",
            "Epoch 96/200\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.3703 - accuracy: 0.8563\n",
            "Epoch 97/200\n",
            "891/891 [==============================] - 0s 463us/step - loss: 0.3701 - accuracy: 0.8530\n",
            "Epoch 98/200\n",
            "891/891 [==============================] - 0s 484us/step - loss: 0.3718 - accuracy: 0.8519\n",
            "Epoch 99/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3684 - accuracy: 0.8530\n",
            "Epoch 100/200\n",
            "891/891 [==============================] - 0s 479us/step - loss: 0.3695 - accuracy: 0.8519\n",
            "Epoch 101/200\n",
            "891/891 [==============================] - 0s 521us/step - loss: 0.3708 - accuracy: 0.8507\n",
            "Epoch 102/200\n",
            "891/891 [==============================] - 0s 476us/step - loss: 0.3684 - accuracy: 0.8507\n",
            "Epoch 103/200\n",
            "891/891 [==============================] - 0s 486us/step - loss: 0.3687 - accuracy: 0.8563\n",
            "Epoch 104/200\n",
            "891/891 [==============================] - 0s 482us/step - loss: 0.3676 - accuracy: 0.8496\n",
            "Epoch 105/200\n",
            "891/891 [==============================] - 0s 467us/step - loss: 0.3672 - accuracy: 0.8552\n",
            "Epoch 106/200\n",
            "891/891 [==============================] - 0s 489us/step - loss: 0.3696 - accuracy: 0.8552\n",
            "Epoch 107/200\n",
            "891/891 [==============================] - 0s 512us/step - loss: 0.3697 - accuracy: 0.8507\n",
            "Epoch 108/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.3665 - accuracy: 0.8586\n",
            "Epoch 109/200\n",
            "891/891 [==============================] - 0s 459us/step - loss: 0.3699 - accuracy: 0.8451\n",
            "Epoch 110/200\n",
            "891/891 [==============================] - 0s 492us/step - loss: 0.3664 - accuracy: 0.8519\n",
            "Epoch 111/200\n",
            "891/891 [==============================] - 0s 472us/step - loss: 0.3665 - accuracy: 0.8563\n",
            "Epoch 112/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3641 - accuracy: 0.8575\n",
            "Epoch 113/200\n",
            "891/891 [==============================] - 0s 479us/step - loss: 0.3645 - accuracy: 0.8462\n",
            "Epoch 114/200\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.3670 - accuracy: 0.8575\n",
            "Epoch 115/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3668 - accuracy: 0.8530\n",
            "Epoch 116/200\n",
            "891/891 [==============================] - 0s 477us/step - loss: 0.3660 - accuracy: 0.8507\n",
            "Epoch 117/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.3642 - accuracy: 0.8597\n",
            "Epoch 118/200\n",
            "891/891 [==============================] - 0s 496us/step - loss: 0.3650 - accuracy: 0.8664\n",
            "Epoch 119/200\n",
            "891/891 [==============================] - 0s 510us/step - loss: 0.3649 - accuracy: 0.8507\n",
            "Epoch 120/200\n",
            "891/891 [==============================] - 0s 512us/step - loss: 0.3664 - accuracy: 0.8519\n",
            "Epoch 121/200\n",
            "891/891 [==============================] - 0s 529us/step - loss: 0.3643 - accuracy: 0.8519\n",
            "Epoch 122/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3635 - accuracy: 0.8541\n",
            "Epoch 123/200\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.3629 - accuracy: 0.8507\n",
            "Epoch 124/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.3625 - accuracy: 0.8608\n",
            "Epoch 125/200\n",
            "891/891 [==============================] - 0s 479us/step - loss: 0.3625 - accuracy: 0.8530\n",
            "Epoch 126/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.3606 - accuracy: 0.8597\n",
            "Epoch 127/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.3592 - accuracy: 0.8575\n",
            "Epoch 128/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.3606 - accuracy: 0.8586\n",
            "Epoch 129/200\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.3632 - accuracy: 0.8541\n",
            "Epoch 130/200\n",
            "891/891 [==============================] - 0s 461us/step - loss: 0.3630 - accuracy: 0.8530\n",
            "Epoch 131/200\n",
            "891/891 [==============================] - 0s 489us/step - loss: 0.3615 - accuracy: 0.8507\n",
            "Epoch 132/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3587 - accuracy: 0.8586\n",
            "Epoch 133/200\n",
            "891/891 [==============================] - 0s 524us/step - loss: 0.3605 - accuracy: 0.8631\n",
            "Epoch 134/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3609 - accuracy: 0.8541\n",
            "Epoch 135/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3573 - accuracy: 0.8552\n",
            "Epoch 136/200\n",
            "891/891 [==============================] - 0s 482us/step - loss: 0.3606 - accuracy: 0.8563\n",
            "Epoch 137/200\n",
            "891/891 [==============================] - 0s 484us/step - loss: 0.3589 - accuracy: 0.8631\n",
            "Epoch 138/200\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.3594 - accuracy: 0.8575\n",
            "Epoch 139/200\n",
            "891/891 [==============================] - 0s 525us/step - loss: 0.3594 - accuracy: 0.8552\n",
            "Epoch 140/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3590 - accuracy: 0.8541\n",
            "Epoch 141/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3562 - accuracy: 0.8552\n",
            "Epoch 142/200\n",
            "891/891 [==============================] - 0s 487us/step - loss: 0.3519 - accuracy: 0.8608\n",
            "Epoch 143/200\n",
            "891/891 [==============================] - 0s 493us/step - loss: 0.3576 - accuracy: 0.8530\n",
            "Epoch 144/200\n",
            "891/891 [==============================] - 0s 517us/step - loss: 0.3564 - accuracy: 0.8519\n",
            "Epoch 145/200\n",
            "891/891 [==============================] - 0s 494us/step - loss: 0.3552 - accuracy: 0.8608\n",
            "Epoch 146/200\n",
            "891/891 [==============================] - 0s 470us/step - loss: 0.3555 - accuracy: 0.8620\n",
            "Epoch 147/200\n",
            "891/891 [==============================] - 0s 483us/step - loss: 0.3520 - accuracy: 0.8620\n",
            "Epoch 148/200\n",
            "891/891 [==============================] - 0s 506us/step - loss: 0.3559 - accuracy: 0.8563\n",
            "Epoch 149/200\n",
            "891/891 [==============================] - 0s 484us/step - loss: 0.3535 - accuracy: 0.8563\n",
            "Epoch 150/200\n",
            "891/891 [==============================] - 0s 495us/step - loss: 0.3532 - accuracy: 0.8608\n",
            "Epoch 151/200\n",
            "891/891 [==============================] - 0s 483us/step - loss: 0.3537 - accuracy: 0.8552\n",
            "Epoch 152/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3551 - accuracy: 0.8575\n",
            "Epoch 153/200\n",
            "891/891 [==============================] - 0s 492us/step - loss: 0.3533 - accuracy: 0.8575\n",
            "Epoch 154/200\n",
            "891/891 [==============================] - 0s 497us/step - loss: 0.3540 - accuracy: 0.8608\n",
            "Epoch 155/200\n",
            "891/891 [==============================] - 0s 490us/step - loss: 0.3538 - accuracy: 0.8608\n",
            "Epoch 156/200\n",
            "891/891 [==============================] - 0s 501us/step - loss: 0.3526 - accuracy: 0.8586\n",
            "Epoch 157/200\n",
            "891/891 [==============================] - 0s 483us/step - loss: 0.3532 - accuracy: 0.8586\n",
            "Epoch 158/200\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.3505 - accuracy: 0.8575\n",
            "Epoch 159/200\n",
            "891/891 [==============================] - 0s 510us/step - loss: 0.3523 - accuracy: 0.8597\n",
            "Epoch 160/200\n",
            "891/891 [==============================] - 0s 496us/step - loss: 0.3539 - accuracy: 0.8620\n",
            "Epoch 161/200\n",
            "891/891 [==============================] - 0s 486us/step - loss: 0.3534 - accuracy: 0.8530\n",
            "Epoch 162/200\n",
            "891/891 [==============================] - 0s 508us/step - loss: 0.3521 - accuracy: 0.8575\n",
            "Epoch 163/200\n",
            "891/891 [==============================] - 0s 518us/step - loss: 0.3520 - accuracy: 0.8631\n",
            "Epoch 164/200\n",
            "891/891 [==============================] - 0s 484us/step - loss: 0.3512 - accuracy: 0.8631\n",
            "Epoch 165/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3507 - accuracy: 0.8575\n",
            "Epoch 166/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3505 - accuracy: 0.8608\n",
            "Epoch 167/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3479 - accuracy: 0.8676\n",
            "Epoch 168/200\n",
            "891/891 [==============================] - 0s 496us/step - loss: 0.3519 - accuracy: 0.8597\n",
            "Epoch 169/200\n",
            "891/891 [==============================] - 0s 521us/step - loss: 0.3472 - accuracy: 0.8664\n",
            "Epoch 170/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.3464 - accuracy: 0.8631\n",
            "Epoch 171/200\n",
            "891/891 [==============================] - 0s 487us/step - loss: 0.3454 - accuracy: 0.8642\n",
            "Epoch 172/200\n",
            "891/891 [==============================] - 0s 487us/step - loss: 0.3499 - accuracy: 0.8597\n",
            "Epoch 173/200\n",
            "891/891 [==============================] - 0s 483us/step - loss: 0.3481 - accuracy: 0.8563\n",
            "Epoch 174/200\n",
            "891/891 [==============================] - 0s 491us/step - loss: 0.3495 - accuracy: 0.8530\n",
            "Epoch 175/200\n",
            "891/891 [==============================] - 0s 496us/step - loss: 0.3477 - accuracy: 0.8620\n",
            "Epoch 176/200\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.3487 - accuracy: 0.8653\n",
            "Epoch 177/200\n",
            "891/891 [==============================] - 0s 481us/step - loss: 0.3483 - accuracy: 0.8642\n",
            "Epoch 178/200\n",
            "891/891 [==============================] - 0s 482us/step - loss: 0.3442 - accuracy: 0.8620\n",
            "Epoch 179/200\n",
            "891/891 [==============================] - 0s 498us/step - loss: 0.3492 - accuracy: 0.8709\n",
            "Epoch 180/200\n",
            "891/891 [==============================] - 0s 491us/step - loss: 0.3475 - accuracy: 0.8653\n",
            "Epoch 181/200\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.3451 - accuracy: 0.8642\n",
            "Epoch 182/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3481 - accuracy: 0.8653\n",
            "Epoch 183/200\n",
            "891/891 [==============================] - 0s 480us/step - loss: 0.3427 - accuracy: 0.8563\n",
            "Epoch 184/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3454 - accuracy: 0.8642\n",
            "Epoch 185/200\n",
            "891/891 [==============================] - 0s 478us/step - loss: 0.3492 - accuracy: 0.8676\n",
            "Epoch 186/200\n",
            "891/891 [==============================] - 0s 508us/step - loss: 0.3419 - accuracy: 0.8586\n",
            "Epoch 187/200\n",
            "891/891 [==============================] - 0s 489us/step - loss: 0.3470 - accuracy: 0.8642\n",
            "Epoch 188/200\n",
            "891/891 [==============================] - 0s 492us/step - loss: 0.3433 - accuracy: 0.8687\n",
            "Epoch 189/200\n",
            "891/891 [==============================] - 0s 488us/step - loss: 0.3487 - accuracy: 0.8575\n",
            "Epoch 190/200\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.3476 - accuracy: 0.8664\n",
            "Epoch 191/200\n",
            "891/891 [==============================] - 0s 505us/step - loss: 0.3439 - accuracy: 0.8676\n",
            "Epoch 192/200\n",
            "891/891 [==============================] - 0s 500us/step - loss: 0.3448 - accuracy: 0.8631\n",
            "Epoch 193/200\n",
            "891/891 [==============================] - 0s 514us/step - loss: 0.3466 - accuracy: 0.8620\n",
            "Epoch 194/200\n",
            "891/891 [==============================] - 0s 512us/step - loss: 0.3464 - accuracy: 0.8653\n",
            "Epoch 195/200\n",
            "891/891 [==============================] - 0s 502us/step - loss: 0.3462 - accuracy: 0.8676\n",
            "Epoch 196/200\n",
            "891/891 [==============================] - 0s 503us/step - loss: 0.3406 - accuracy: 0.8687\n",
            "Epoch 197/200\n",
            "891/891 [==============================] - 0s 476us/step - loss: 0.3446 - accuracy: 0.8687\n",
            "Epoch 198/200\n",
            "891/891 [==============================] - 0s 485us/step - loss: 0.3399 - accuracy: 0.8676\n",
            "Epoch 199/200\n",
            "891/891 [==============================] - 0s 487us/step - loss: 0.3462 - accuracy: 0.8721\n",
            "Epoch 200/200\n",
            "891/891 [==============================] - 0s 509us/step - loss: 0.3415 - accuracy: 0.8631\n",
            "418/418 [==============================] - 0s 154us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JreBojLdeMT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_df.index,\n",
        "    'Survived': prediction[:,0],\n",
        "})\n",
        "\n",
        "submission.sort_values('PassengerId', inplace=True)    \n",
        "submission.to_csv('Titanic-test_results.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unUEY4_Tl-Gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "779e9f97-53ef-4941-e562-839ecdb51092"
      },
      "source": [
        "ls /"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbin\u001b[0m/                                       \u001b[01;34metc\u001b[0m/    \u001b[01;34mopt\u001b[0m/    \u001b[01;34msys\u001b[0m/\n",
            "\u001b[01;34mboot\u001b[0m/                                      \u001b[01;34mhome\u001b[0m/   \u001b[01;34mproc\u001b[0m/   \u001b[01;34mtensorflow-1.15.2\u001b[0m/\n",
            "\u001b[01;34mcontent\u001b[0m/                                   \u001b[01;34mlib\u001b[0m/    \u001b[01;34mroot\u001b[0m/   \u001b[30;42mtmp\u001b[0m/\n",
            "\u001b[01;34mdatalab\u001b[0m/                                   \u001b[01;34mlib32\u001b[0m/  \u001b[01;34mrun\u001b[0m/    \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mdev\u001b[0m/                                       \u001b[01;34mlib64\u001b[0m/  \u001b[01;34msbin\u001b[0m/   \u001b[01;34musr\u001b[0m/\n",
            "dlib-19.18.0-cp27-cp27mu-linux_x86_64.whl  \u001b[01;34mmedia\u001b[0m/  \u001b[01;34msrv\u001b[0m/    \u001b[01;34mvar\u001b[0m/\n",
            "dlib-19.18.0-cp36-cp36m-linux_x86_64.whl   \u001b[01;34mmnt\u001b[0m/    \u001b[01;34mswift\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAQN5UcPmLxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4aa4e486-903d-4a95-9072-65df029f85e6"
      },
      "source": [
        "ls content/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'content/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nc1O9R5mQ6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}